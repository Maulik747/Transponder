{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ac22dd84-04f5-41d5-a50b-f01052025aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftType\n",
    "from BidirectionalSwitchForLoraLlama import LoraLlamaBidirectionalSwitch\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftType, PeftModel\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from DataHandling import MLMSlimPajamaDataset, dataloader_collate_function\n",
    "import pandas as pd\n",
    "import gc\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR\n",
    "\n",
    "model_checkpoint = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0fd7b3-d2f0-4a6c-acf1-8509ac04d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9ab76c-b215-493c-9b6c-0878b3e62115",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AutoModelForCausalLM.from_pretrained(model_checkpoint, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9463c566-dfb7-436c-ae69-820226372d2c",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011533b-aab3-43c6-bcff-38e323d46dfa",
   "metadata": {},
   "source": [
    "Take the first 1000 sentences from the SlimPajama dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912cb6f2-6b82-47a2-b23e-505198dd2e7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dae22268ced4d0ea0dd28217523f943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/5912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1bd736cd724261b3b3245a01bf1de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/5912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_files = [\"train/chunk1/*.jsonl.zst\"]\n",
    "slim_pajama = load_dataset(\"cerebras/SlimPajama-627B\", data_files=data_files, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0f21dd7e-d18e-4ff0-9bd8-42b2a5266d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▌                                                                                                                                                        | 1/100 [00:00<00:39,  2.54it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (5199 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 99/100 [00:00<00:00, 178.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = MLMSlimPajamaDataset(tokenizer, 100, 0.2)\n",
    "dataset.create_from_dataset(slim_pajama[\"train\"])\n",
    "dataset.export_dataset(\"slim_pajama_100_samples_20_percent_masking.json\")\n",
    "# dataset.load_from_disk(\"slim_pajama_first_1000.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b405a70-562e-4c74-9745-bba4ea2cb4e5",
   "metadata": {},
   "source": [
    "## Define MLM head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b5021a11-50db-4564-8bf2-864c08213096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLMHead(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(2048, 32000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b79c8-8887-481b-b248-a73212263f87",
   "metadata": {},
   "source": [
    "## Add embedding of the [MASK] token to the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2c441a95-e470-48f5-b324-06493d238c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32001, 2048)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.resize_token_embeddings(32001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2944f7ba-79dc-4454-a8d9-f0e9f5a142d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32001, 2048)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model.embed_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644a268-a26d-44a5-8a18-82205ceb5b3d",
   "metadata": {},
   "source": [
    "The initial embedding of the [MASK] token needs to be learned, so requires_grad for this parameter must be set to True. Thus, preparing to receive a copy of the section of the embedding matrix via the get_mask_token_embedding_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "15e2368f-a5fc-47ab-babb-05480a9e01a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_token_embedding(llm, tokenizer):\n",
    "    for parameter in llm.parameters():\n",
    "        if param.shape == torch.Size([tokenizer.vocab_size + 1, 2048]):\n",
    "            return parameter[tokenizer.vocab_size].clone()\n",
    "\n",
    "def save_mask_token_embedding(llm, tokenizer):\n",
    "    for parameter in llm.parameters():\n",
    "        if param.shape == torch.Size([tokenizer.vocab_size + 1, 2048]):\n",
    "            mask_token_embedding_weights = parameter[tokenizer.vocab_size].clone().detach()\n",
    "            with open(\"mask_token_embedding_weights.pt\", \"wb\") as mask_embedding_weights_file:\n",
    "                torch.save(mask_token_embedding_weights, mask_embedding_weights_file)\n",
    "                return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a781fe75-61ed-4070-ac44-ab8553dc6321",
   "metadata": {},
   "source": [
    "## Define the model with LoRA weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6da6c8c4-675f-4034-8e0e-ff719a4e50bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,  # Type of task (e.g., causal language modeling)\n",
    "        r=8,  # Low-rank dimension\n",
    "        lora_alpha=32,  # Scaling factor\n",
    "        lora_dropout=0.1,  # Dropout probability for LoRA\n",
    "        bias=\"none\",  # Bias configuration\n",
    "    )\n",
    "lora_model = get_peft_model(llm, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "71019fb2-9db7-4979-9fb5-c07364bcf53a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param.shape = torch.Size([32001, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([256, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([8, 2048]) param.requires_grad = True\n",
      "param.shape = torch.Size([256, 8]) param.requires_grad = True\n",
      "param.shape = torch.Size([2048, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([5632, 2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048, 5632]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([2048]) param.requires_grad = False\n",
      "param.shape = torch.Size([32001, 2048]) param.requires_grad = False\n"
     ]
    }
   ],
   "source": [
    "for param in lora_model.parameters():\n",
    "    print(f\"param.shape = {param.shape} param.requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1335b-c0a3-4637-91a5-dadebd5baaa8",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89dda37-d2c2-479f-9846-a626187d725c",
   "metadata": {},
   "source": [
    "### Preparing parameters for training\n",
    "\n",
    "Three groups:\n",
    "- LoRA parameters\n",
    "- MLM head parameters\n",
    "- Mask token representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21582131-aa3c-4ba1-9521-e0d4a9b0553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = input(\"Enter the name of the experiment\")\n",
    "# re-initializing everything so that the model parameters are reset\n",
    "lora_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,  # Type of task (e.g., causal language modeling)\n",
    "        r=8,  # Low-rank dimension\n",
    "        lora_alpha=32,  # Scaling factor\n",
    "        lora_dropout=0.1,  # Dropout probability for LoRA\n",
    "        bias=\"none\",  # Bias configuration\n",
    "    )\n",
    "lora_model = get_peft_model(llm, lora_config)\n",
    "\n",
    "mask_token_representation = get_mask_token_embedding(lora_model, tokenizer)\n",
    "mask_token_representation.requires_grad = True\n",
    "\n",
    "mlm_head = MLMHead()\n",
    "batch_size = 4\n",
    "# checked that the maximum batch size is 4, using 8 led to a CudaOutOfMemoryError\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=lambda x: dataloader_collate_function(x, tokenizer, 2048))\n",
    "parameters = list([mask_token_representation]) + list(lora_model.parameters()) + list(mlm_head.parameters())\n",
    "writer = SummaryWriter(f\"runs/spaudel/{experiment_name}\")\n",
    "num_epochs = 10\n",
    "num_batches = len(dataloader)\n",
    "\n",
    "writer.add_text(\"init_lr\", str(init_lr))\n",
    "writer.add_text(\"lr_scheduler\", str(lr_scheduler))\n",
    "writer.add_text(\"num_epochs\", str(num_epochs))\n",
    "writer.add_text(\"batch_size\", str(batch_size))\n",
    "last_epoch_trained = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bdf4b8d6-81ab-4f95-9426-320d703befa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f\"runs/spaudel/100_samples_with_20_percent_masking_babied_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ee05bedd-b7b0-4543-8129-55413c08dee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 29 Iteration: 24: : 25it [01:11,  2.86s/it]\n",
      "Epoch : 30 Iteration: 24: : 25it [01:10,  2.82s/it]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "init_lr = 1e-6\n",
    "optimizer = Adam(parameters, lr=init_lr)\n",
    "lr_scheduler = ExponentialLR(optimizer, 1)\n",
    "last_epoch_trained = 29\n",
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "    average_loss = 0\n",
    "    writer.add_scalar(\"learning_rate\", lr_scheduler.get_last_lr()[0], last_epoch_trained + epoch_idx)\n",
    "    for iteration_idx, batch in (pbar:=tqdm(enumerate(dataloader))):\n",
    "        pbar.set_description(f\"Epoch : {last_epoch_trained + epoch_idx} Iteration: {iteration_idx}\")\n",
    "        optimizer.zero_grad()\n",
    "        masked_input_ids, attention_mask, original_input_ids = batch\n",
    "        masked_input_ids, attention_mask, original_input_ids = (\n",
    "            masked_input_ids.to(lora_model.device),\n",
    "            attention_mask.to(lora_model.device), \n",
    "            original_input_ids.to(lora_model.device)\n",
    "        )\n",
    "        with LoraLlamaBidirectionalSwitch(lora_model):\n",
    "            model_output = lora_model(input_ids=masked_input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        last_hidden_state = model_output.hidden_states[-1]\n",
    "        mlm_head = mlm_head.to(last_hidden_state.device)\n",
    "        scores = mlm_head.forward(last_hidden_state)\n",
    "        dists = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        ce_loss_one_hot_encodings = torch.nn.functional.one_hot(original_input_ids, num_classes=32000)\n",
    "        ce_loss_intermediate = (ce_loss_one_hot_encodings * torch.log(dists)).sum(dim=-1)\n",
    "        mask_tokens_positions = masked_input_ids == tokenizer.vocab_size\n",
    "        loss = ce_loss_intermediate[mask_tokens_positions].mean() * -1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.detach().cpu().item()\n",
    "        writer.add_scalar(\"training_loss\", loss, (last_epoch_trained+epoch_idx) * num_batches + iteration_idx)\n",
    "        average_loss += loss\n",
    "    average_loss /= num_batches\n",
    "    lr_scheduler.step(average_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b7c0403a-57ae-48cb-a086-6291bceecd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pasu/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/pasu/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lora_model.save_pretrained(\"babied_lr_peft_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eabc1694-8e67-4a93-8822-fa2d20fb2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_head = mlm_head.to(\"cpu\")\n",
    "torch.save(mlm_head.state_dict(), \"mlm_head.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9cd7662f-a58b-411f-ac6f-45c8b79c0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_mask_token_embedding(lora_model, tokenizer) not needed, since PeFT handles saving the embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "42840195-a56c-4379-b374-2e612f7b109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model= PeftModel.from_pretrained(llm, \"babied_lr_peft_weights\")\n",
    "merged_model= merged_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f205c7ae-cc3e-4eb2-b01f-3458fe1918d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32001, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32001, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dee63204-511b-41e1-a5e8-8eb773e45369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_head_reloaded = MLMHead()\n",
    "mlm_head_reloaded.load_state_dict(torch.load(\"mlm_head.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed3a60-a48d-4689-b840-f0333556881c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
